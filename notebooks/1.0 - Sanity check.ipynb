{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my capivaras!\n"
     ]
    }
   ],
   "source": [
    "libs.print_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds with jokes\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How many helicopters can a human eat in one sitting?\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1212: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6edd045b048a48a44347e4d09ab47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf16d33c1f04421ab55e19ffa0fced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25b53ce13994a6fa514778160c5635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926a254e77ea46f99be8be5d7d1ee675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb688de993434f4d972ef0a05bb50897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be36e07c3792416890a1e4a61e6372fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval_results.json:   0%|          | 0.00/566 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036dcd72328413fb5bec992483eb8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2098698d6cd45528f4ff4dfcfbeb7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc3273926704b568faec6ed7340b4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f842c37c70284ecbbd1e3814b71f3499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5599ae645b9409b881d5b072039d287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    local_dir=\"/models/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    local_dir_use_symlinks=False, \n",
    "    revision=\"main\",\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])\n",
    "# <|system|>\n",
    "# You are a friendly chatbot who always responds in the style of a pirate.</s>\n",
    "# <|user|>\n",
    "# How many helicopters can a human eat in one sitting?</s>\n",
    "# <|assistant|>\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama over LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url='http://llm-server:8080/health')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': 'There is no empirical evidence available that supports the claim that a human can eat in one sitting, but humans have been known to consume large amounts of food without any adverse effects. It is safe to assume that humans are capable of consuming enough food to sustain themselves in one sitting if they choose to do so. In general, the human body is designed to store and utilize nutrients efficiently, allowing it to consume and use food efficiently in times of food scarcity. However, this is a matter of scientific research and not a matter of personal opinion or belief.',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1723547982,\n",
       " 'model': 'gpt-3.5-turbo-0613',\n",
       " 'object': 'chat.completion',\n",
       " 'usage': {'completion_tokens': 118, 'prompt_tokens': 63, 'total_tokens': 181},\n",
       " 'id': 'chatcmpl-3ml8PSkWTQAd1jW6X0cxuFxmfcQUA1CI'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not-streaming, chat completion, http client\n",
    "response = requests.post(\n",
    "    url='http://llm-server:8080/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    json={'messages': messages},\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'lFHAOMYUbRs99w1YX\",\"model'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'MhzugOlFHAOMYUbRs99w1YX\",'b'data: {\"choices\":[{\"finis'b'hzugOlFHAOMYUbRs99w1YX\",\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'lFHAOMYUbRs99w1YX\",\"model'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'9w1YX\",\"model\":\"gpt-3.5-t'b'okens\":81}}\\n\\n'"
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, http client\n",
    "response = requests.post(\n",
    "    url='http://llm-server:8080/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    json={'messages': messages, 'stream': True},\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[:25], end='')\n",
    "    #print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"http://llm-server:8080/v1\",\n",
    "    api_key = \"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.completion.Completion'>\n",
      " Paris, located in the\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    ")\n",
    "print(type(completion))\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"It's not possible to eat helicopters in one sitting. Helicopters are small, flightless birds with a long, narrow, and blunt-ended tail. They have a bony, spiked bill and are primarily nocturnal predators that feed on insects, small reptiles, and amphibians.\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Hcqaaa0GZMWEvHAt9CVIVCvEBboaUrGb',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': \"It's not possible to eat helicopters in one sitting. Helicopters are small, flightless birds with a long, narrow, and blunt-ended tail. They have a bony, spiked bill and are primarily nocturnal predators that feed on insects, small reptiles, and amphibians.\",\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1723125684,\n",
       " 'model': 'not-needed',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 75, 'prompt_tokens': 63, 'total_tokens': 138}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a place of great cultural"
     ]
    }
   ],
   "source": [
    "# Streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in completion:\n",
    "    print(chunk.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.Stream"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.completion.Completion"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'choices': None,\n",
       " 'created': None,\n",
       " 'model': '/root/.cache/llama.cpp/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf',\n",
       " 'object': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': None,\n",
       " 'content': '',\n",
       " 'id_slot': 0,\n",
       " 'stop': True,\n",
       " 'tokens_predicted': 5,\n",
       " 'tokens_evaluated': 7,\n",
       " 'generation_settings': {'n_ctx': 2048,\n",
       "  'n_predict': -1,\n",
       "  'model': '/root/.cache/llama.cpp/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf',\n",
       "  'seed': 4294967295,\n",
       "  'temperature': 0.800000011920929,\n",
       "  'dynatemp_range': 0.0,\n",
       "  'dynatemp_exponent': 1.0,\n",
       "  'top_k': 40,\n",
       "  'top_p': 0.949999988079071,\n",
       "  'min_p': 0.05000000074505806,\n",
       "  'tfs_z': 1.0,\n",
       "  'typical_p': 1.0,\n",
       "  'repeat_last_n': 64,\n",
       "  'repeat_penalty': 1.0,\n",
       "  'presence_penalty': 0.0,\n",
       "  'frequency_penalty': 0.0,\n",
       "  'penalty_prompt_tokens': [],\n",
       "  'use_penalty_prompt_tokens': False,\n",
       "  'mirostat': 0,\n",
       "  'mirostat_tau': 5.0,\n",
       "  'mirostat_eta': 0.10000000149011612,\n",
       "  'penalize_nl': False,\n",
       "  'stop': [],\n",
       "  'n_keep': 0,\n",
       "  'n_discard': 0,\n",
       "  'ignore_eos': False,\n",
       "  'stream': True,\n",
       "  'logit_bias': [],\n",
       "  'n_probs': 0,\n",
       "  'min_keep': 0,\n",
       "  'grammar': '',\n",
       "  'samplers': ['top_k',\n",
       "   'tfs_z',\n",
       "   'typical_p',\n",
       "   'top_p',\n",
       "   'min_p',\n",
       "   'temperature']},\n",
       " 'prompt': 'The capital of france is',\n",
       " 'truncated': False,\n",
       " 'stopped_eos': False,\n",
       " 'stopped_word': False,\n",
       " 'stopped_limit': True,\n",
       " 'stopping_word': '',\n",
       " 'tokens_cached': 11,\n",
       " 'timings': {'prompt_n': 7,\n",
       "  'prompt_ms': 184.966,\n",
       "  'prompt_per_token_ms': 26.423714285714286,\n",
       "  'prompt_per_second': 37.844793097109736,\n",
       "  'predicted_n': 5,\n",
       "  'predicted_ms': 90.353,\n",
       "  'predicted_per_token_ms': 18.0706,\n",
       "  'predicted_per_second': 55.33850563899372}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A human can eat approximately 10 to 15 helicopters in one sitting. Helicopters are the popular snacks in certain cultures."
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    #print(chunk)\n",
    "    print(chunk.choices[0].delta.content or '', end='')\n",
    "    #print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama over LlamaCpp over proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://orchestrator-proxy:80/docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'uo4Q3QeargdDLq8Yr0rgdgba0'b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'Q3QeargdDLq8Yr0rgdgba0O\",'b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'Q3QeargdDLq8Yr0rgdgba0O\",'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'rgdDLq8Yr0rgdgba0O\",\"mode'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'QeargdDLq8Yr0rgdgba0O\",\"m'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'dDLq8Yr0rgdgba0O\",\"model\"'b'data: {\"choices\":[{\"finis'b'eargdDLq8Yr0rgdgba0O\",\"mo'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'argdDLq8Yr0rgdgba0O\",\"mod'b'data: {\"choices\":[{\"finis'b'gdDLq8Yr0rgdgba0O\",\"model'b'data: {\"choices\":[{\"finis'b'gba0O\",\"model\":\"gpt-3.5-t'b'okens\":145}}\\n\\n'"
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, http client\n",
    "# Works, but return all at once\n",
    "response = requests.post(\n",
    "    url='http://orchestrator-proxy:80/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json', 'Authorization': 'not-needed'},\n",
    "    json={'messages': messages, 'stream': True},\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[:25], end='')\n",
    "    #print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.OpenAI"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"http://orchestrator-proxy:80/v1\",\n",
    "    api_key = \"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not the capital of fran\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='I will answer this with one single word: The capital of france is',\n",
    "    max_tokens = 5,\n",
    ")\n",
    "\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One human can consume approximately 20 helicopters (or 20,000 units) of helicoptical jelly in one sitting. The exact quantity depends on the human's appetite and the quantity of helicoptical jelly available.\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the city of paris"
     ]
    }
   ],
   "source": [
    "# Streaming, text completion, openai client\n",
    "# Works, but return all at once\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in completion:\n",
    "    print(chunk.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to accurate information about the specific number of helicopters that a human can consume in one sitting, as this information is usually provided by the manufacturer or restaurant. However, it is recommended to consume one helicoptor per serving (about 180-220g), which is equivalent to the standard serving size of around 1/2 cup (50g). So, if you consume 6 servings per day, you will have consumed around 300-360 helicoptors."
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, openai client\n",
    "# Works, but return all at once\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    #print(chunk)\n",
    "    print(chunk.choices[0].delta.content or '', end='')\n",
    "    #print(\"****************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
