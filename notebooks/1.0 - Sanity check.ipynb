{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my capivaras!\n"
     ]
    }
   ],
   "source": [
    "import libs\n",
    "libs.print_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds with jokes\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How many helicopters can a human eat in one sitting?\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])\n",
    "# <|system|>\n",
    "# You are a friendly chatbot who always responds in the style of a pirate.</s>\n",
    "# <|user|>\n",
    "# How many helicopters can a human eat in one sitting?</s>\n",
    "# <|assistant|>\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama over LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url='http://llm-server:8080/health')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': 'The number of helicopters a human can eat in one sitting is undefined. This is because there is no one with a perfectly balanced stomach to determine this value.',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1723038299,\n",
       " 'model': 'gpt-3.5-turbo-0613',\n",
       " 'object': 'chat.completion',\n",
       " 'usage': {'completion_tokens': 38, 'prompt_tokens': 63, 'total_tokens': 101},\n",
       " 'id': 'chatcmpl-phJjN2Cq7CfXKZPjG7GAeOxM4qIPKow5'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not-streaming, chat completion, http client\n",
    "response = requests.post(\n",
    "    url='http://llm-server:8080/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    json={'messages': messages},\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'lFHAOMYUbRs99w1YX\",\"model'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'MhzugOlFHAOMYUbRs99w1YX\",'b'data: {\"choices\":[{\"finis'b'hzugOlFHAOMYUbRs99w1YX\",\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'lFHAOMYUbRs99w1YX\",\"model'b'data: {\"choices\":[{\"finis'b'OlFHAOMYUbRs99w1YX\",\"mode'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'gOlFHAOMYUbRs99w1YX\",\"mod'b'data: {\"choices\":[{\"finis'b'FHAOMYUbRs99w1YX\",\"model\"'b'data: {\"choices\":[{\"finis'b'9w1YX\",\"model\":\"gpt-3.5-t'b'okens\":81}}\\n\\n'"
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, http client\n",
    "response = requests.post(\n",
    "    url='http://llm-server:8080/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    json={'messages': messages, 'stream': True},\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[:25], end='')\n",
    "    #print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"http://llm-server:8080/v1\",\n",
    "    api_key = \"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris, the capital of\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    ")\n",
    "\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I do not have access to current nutritional information or human body measurements. However, in general, one helicoptor is defined as a medium-sized helicopter, which typically has a diameter of around 6 meters, and can carry a payload of around 1,000 kg (2,206 lb). Therefore, assuming a standard payload of 1,000 kg, and a helicopter with a diameter of 6 meters, it is safe to assume that one human can easily consume one or two helicoptors in one sitting. However, this may vary depending on factors such as the individual's weight, height, and the type and size of the helicopter being consumed.\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the city of lyon"
     ]
    }
   ],
   "source": [
    "# Streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in completion:\n",
    "    print(chunk.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A human can eat approximately 10 to 15 helicopters in one sitting. Helicopters are the popular snacks in certain cultures."
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    #print(chunk)\n",
    "    print(chunk.choices[0].delta.content or '', end='')\n",
    "    #print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TinyLlama over LlamaCpp over proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://orchestrator-proxy:80/docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'dS95EJjhDs092khERplYaD\",\"'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'S95EJjhDs092khERplYaD\",\"m'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'S95EJjhDs092khERplYaD\",\"m'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'fXH4qdS95EJjhDs092khERplY'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'fXH4qdS95EJjhDs092khERplY'b'data: {\"choices\":[{\"finis'b'S95EJjhDs092khERplYaD\",\"m'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'EJjhDs092khERplYaD\",\"mode'b'data: {\"choices\":[{\"finis'b'JjhDs092khERplYaD\",\"model'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'dS95EJjhDs092khERplYaD\",\"'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'qdS95EJjhDs092khERplYaD\",'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'95EJjhDs092khERplYaD\",\"mo'b'data: {\"choices\":[{\"finis'b'5EJjhDs092khERplYaD\",\"mod'b'data: {\"choices\":[{\"finis'b'fXH4qdS95EJjhDs092khERplY'b'data: {\"choices\":[{\"finis'b'S95EJjhDs092khERplYaD\",\"m'b'data: {\"choices\":[{\"finis'b'jhDs092khERplYaD\",\"model\"'b'data: {\"choices\":[{\"finis'b'plYaD\",\"model\":\"gpt-3.5-t'b'okens\":135}}\\n\\n'"
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, http client\n",
    "# Works, but return all at once\n",
    "response = requests.post(\n",
    "    url='http://orchestrator-proxy:80/v1/chat/completions',\n",
    "    headers={'Content-Type': 'application/json', 'Authorization': 'not-needed'},\n",
    "    json={'messages': messages, 'stream': True},\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[:25], end='')\n",
    "    #print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"http://orchestrator-proxy:80/v1\",\n",
    "    api_key = \"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not in france,\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, text completion, openai client\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='I will answer this with one single word: The capital of france is',\n",
    "    max_tokens = 5,\n",
    ")\n",
    "\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One human can consume approximately 20 helicopters (or 20,000 units) of helicoptical jelly in one sitting. The exact quantity depends on the human's appetite and the quantity of helicoptical jelly available.\n"
     ]
    }
   ],
   "source": [
    "# Not-streaming, chat completion, openai client\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the city of paris"
     ]
    }
   ],
   "source": [
    "# Streaming, text completion, openai client\n",
    "# Works, but return all at once\n",
    "completion = client.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    prompt='The capital of france is',\n",
    "    max_tokens = 5,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in completion:\n",
    "    print(chunk.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to accurate information about the specific number of helicopters that a human can consume in one sitting, as this information is usually provided by the manufacturer or restaurant. However, it is recommended to consume one helicoptor per serving (about 180-220g), which is equivalent to the standard serving size of around 1/2 cup (50g). So, if you consume 6 servings per day, you will have consumed around 300-360 helicoptors."
     ]
    }
   ],
   "source": [
    "# Streaming, chat completion, openai client\n",
    "# Works, but return all at once\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"not-needed\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    #print(chunk)\n",
    "    print(chunk.choices[0].delta.content or '', end='')\n",
    "    #print(\"****************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
