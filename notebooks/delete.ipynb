{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05b1bc6-f2ca-47d1-9039-9e9b718ca660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from libs.utils.connector_llm import *\n",
    "from libs.plugins.plugin_capital import PluginCapital\n",
    "from libs.plugin_converter.semantic_kernel_v0_to_openai_function import generate_callables, generate_definitions\n",
    "\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a656adfa-70f5-453b-889e-b8d7f04cafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_connector_llm(\n",
    "    provider='azure_openai',\n",
    "    modelname=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "    version=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\").split('-')[-1],\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d64099-ac5c-4b92-8b44-4f79c5164c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_connector_llm(\n",
    "    provider='openai',\n",
    "    modelname='not-needed',\n",
    "    version='not-needed',\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url='http://llm-server:8080/v1',\n",
    "        api_key='not-needed',\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f0e2bbd-896a-4d7f-bdc2-ec3f82a8809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a human and this is my first post on the chatbot. I want to know more about the chatbot's capabilities and how it can assist me in my daily tasks. Please let me know more about the chatbot's features and how it can help me in my work or personal life. I'm excited to hear more about the chatbot's potential for improving my experience.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text completion, normal\n",
    "text_completion = llm.chat_completion(\n",
    "    messages=[ChatCompletionMessage(content='hi', role='user')],\n",
    ")\n",
    "text_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc022ef-ade3-45e9-a39c-33218af8bb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9uDilen3g01jR0gljTkxk2R6cf944', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"country\":\"Brazil\"}', name='PluginCapital_get_capital'), tool_calls=None), content_filter_results={})], created=1723186139, model='gpt-35-turbo', object='chat.completion', service_tier=None, system_fingerprint='fp_811936bd4f', usage=CompletionUsage(completion_tokens=17, prompt_tokens=230, total_tokens=247), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatCompletion\nchoices.0.message.content\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# chat completion, normal\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mChatCompletionMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myou are an AI assistant that answer only with function calls, nothing else. Always use the tools, do not answer without the tools.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mChatCompletionMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of brasil?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_definitions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerate_definitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPluginCapital\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPluginCapital\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m chat_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/src/libs/utils/connector_llm.py:136\u001b[0m, in \u001b[0;36mConnectorLLMOpenAI.chat_completion\u001b[0;34m(self, messages, tool_definitions)\u001b[0m\n\u001b[1;32m    127\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    128\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelname,\n\u001b[1;32m    129\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[m\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters\u001b[38;5;241m.\u001b[39mdict(),\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat_completion)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatCompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatCompletion\nchoices.0.message.content\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type"
     ]
    }
   ],
   "source": [
    "# chat completion, normal\n",
    "chat_completion = llm.chat_completion(\n",
    "    messages=[\n",
    "        ChatCompletionMessage(**{'role': 'system', 'content': 'you are an AI assistant that answer only with function calls, nothing else. Always use the tools, do not answer without the tools.'}),\n",
    "        ChatCompletionMessage(**{'role': 'user', 'content': 'What is the capital of brasil?'}),\n",
    "    ],\n",
    "    tool_definitions = generate_definitions([(PluginCapital(), \"PluginCapital\")])\n",
    "\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4c4de-12e3-4d44-b5fc-8c09940cf1a4",
   "metadata": {},
   "source": [
    "```\n",
    "ChatCompletion(id='chatcmpl-9uDilen3g01jR0gljTkxk2R6cf944', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"country\":\"Brazil\"}', name='PluginCapital_get_capital'), tool_calls=None), content_filter_results={})], created=1723186139, model='gpt-35-turbo', object='chat.completion', service_tier=None, system_fingerprint='fp_811936bd4f', usage=CompletionUsage(completion_tokens=17, prompt_tokens=230, total_tokens=247), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1d748-2fab-4d32-8e7c-aea8e8a5f89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d671f7a-41aa-4568-989b-f4aff023b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you're facing some difficulties. I'm glad to hear that you're doing your best to overcome them. Can you provide me with some tips on how I can better manage my time and prioritize my tasks? Also, I'm curious about your current workout routine. Have you tried any new exercises or exercising styles lately?"
     ]
    }
   ],
   "source": [
    "# chat completion, stream\n",
    "chat_completion_stream = llm.chat_completion_stream(\n",
    "    messages=[ChatCompletionMessage(content='hi', role='user')],\n",
    ")\n",
    "for chunk in chat_completion_stream:\n",
    "    if len(chunk.choices) > 0:\n",
    "        print(chunk.choices[0].message.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cccd57f-604b-4da1-aa60-140f3653131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the text: The latest marketing trend is a game-changer for small businesses.\\n\\nBased on the text material above, generate the response to the following quesion or instruction: What is the latest marketing trend that small businesses are embracing, as mentioned in the given text material?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat completion, normal, async\n",
    "chat_completion = await llm.chat_completion_async(\n",
    "    messages=[ChatCompletionMessage(content='hi', role='user')],\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "332cdc60-bbff-488e-8cda-b940eed452b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Name],\n",
      "\n",
      "It's with much anticipation that I write to you, my dear friend. I hope this letter finds you in good health and spirits. I'm excited to share with you the wonderful news that we've been working on together for quite some time.\n",
      "\n",
      "I've been working closely with [Name of team member], who has been tasked with designing and developing a new app that's poised to revolutionize the industry. The app will be designed with your needs in mind, and I'm confident that it will be the talk of the town in no time.\n",
      "\n",
      "I've been working closely with [Name of team member], who has been tasked with developing"
     ]
    }
   ],
   "source": [
    "# chat completion, stream, async\n",
    "chat_completion_stream = llm.chat_completion_stream_async(\n",
    "    messages=[ChatCompletionMessage(content='hi', role='user')],\n",
    ")\n",
    "async for chunk in chat_completion_stream:\n",
    "    if len(chunk.choices) > 0:\n",
    "        print(chunk.choices[0].message.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c0d72-2044-45c4-92b0-282c7031b1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d31fa-7837-4761-96ce-581f6ff6877b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64720c-9b65-4a9f-bb53-f6c76caa21b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2631d6c-416b-4fdc-baaf-0c71a655a798",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object AzureOpenAI can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI\n\u001b[0;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m AzureOpenAI(\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \n\u001b[1;32m      6\u001b[0m     api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-05-01-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: object AzureOpenAI can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55932dc7-3f09-4463-a1ab-01bb4d5c4479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "chat_completion = await client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "    messages= [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the differences between Azure Machine Learning and Azure AI services?\"\n",
    "    }],\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    ")\n",
    "print(type(chat_completion))\n",
    "#print(chat_completion_stream.to_dict().keys())\n",
    "#print(chat_completion_stream.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "332374a9-c1c8-4d27-a208-087ab12a4f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"id\": \"chatcmpl-9tzSsNLPmKdZVoYLlCqdJzBzdWGJX\",\\n  \"choices\": [\\n    {\\n      \"finish_reason\": \"stop\",\\n      \"index\": 0,\\n      \"logprobs\": null,\\n      \"message\": {\\n        \"content\": \"Azure Machine Learning is a cloud-based service that provides tools and capabilities for building, training, and deploying machine learning models. It is designed for data scientists and machine learning engineers to develop and manage their machine learning workflows.\\\\n\\\\nAzure AI services, on the other hand, are a suite of pre-built AI capabilities that can be easily integrated into applications. These services include computer vision, natural language processing, speech recognition, and decision-making capabilities. They are designed for developers to add AI capabilities to their applications without needing to build and train their own machine learning models.\\\\n\\\\nIn summary, Azure Machine Learning is focused on building and managing custom machine learning models, while Azure AI services provide pre-built AI capabilities for developers to integrate into their applications.\",\\n        \"role\": \"assistant\"\\n      },\\n      \"content_filter_results\": {\\n        \"hate\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"protected_material_code\": {\\n          \"filtered\": false,\\n          \"detected\": false\\n        },\\n        \"protected_material_text\": {\\n          \"filtered\": false,\\n          \"detected\": false\\n        },\\n        \"self_harm\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"sexual\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"violence\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        }\\n      }\\n    }\\n  ],\\n  \"created\": 1723131338,\\n  \"model\": \"gpt-35-turbo\",\\n  \"object\": \"chat.completion\",\\n  \"system_fingerprint\": \"fp_811936bd4f\",\\n  \"usage\": {\\n    \"completion_tokens\": 144,\\n    \"prompt_tokens\": 20,\\n    \"total_tokens\": 164\\n  },\\n  \"prompt_filter_results\": [\\n    {\\n      \"prompt_index\": 0,\\n      \"content_filter_results\": {\\n        \"hate\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"jailbreak\": {\\n          \"filtered\": false,\\n          \"detected\": false\\n        },\\n        \"self_harm\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"sexual\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        },\\n        \"violence\": {\\n          \"filtered\": false,\\n          \"severity\": \"safe\"\\n        }\\n      }\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53575421-59f8-470a-a185-904aa66a97b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chat_completion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70528ed-6a69-44ca-b6cb-80704efafb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'close',\n",
       " 'gi_code',\n",
       " 'gi_frame',\n",
       " 'gi_running',\n",
       " 'gi_yieldfrom',\n",
       " 'send',\n",
       " 'throw']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_completion_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c38dbaea-f638-4aac-a1ca-9a9a29fa44f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat_completion_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "chat_completion_stream.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6269a18-49bf-4488-a095-02af2bd73d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(chat_completion_stream))\n",
    "#print(chat_completion_stream.to_dict().keys())\n",
    "#print(chat_completion_stream.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37e2b75-6c55-4fba-80c3-e7e2873a1c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.Stream'>\n"
     ]
    }
   ],
   "source": [
    "chat_completion_stream = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "    messages= [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the differences between Azure Machine Learning and Azure AI services?\"\n",
    "    }],\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=True\n",
    ")\n",
    "print(type(chat_completion_stream))\n",
    "#print(chat_completion_stream.to_dict().keys())\n",
    "#print(chat_completion_stream.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272d1f88-29a7-4720-83d3-d19993bbd9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_completion_stream._iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7efb62-f37d-40a1-970d-2e0e1eb9d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = chat_completion_stream.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acbb49de-a553-485f-a50f-ebe8de5ad28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion_chunk.ChatCompletionChunk"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "226e0799-de16-47a0-85da-5c67137dab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9tz7h8i01wQjgXcQoGLRqtE4ULahc',\n",
       " 'choices': [{'delta': {'content': '',\n",
       "    'function_call': None,\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'tool_calls': None},\n",
       "   'finish_reason': None,\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'content_filter_results': {}}],\n",
       " 'created': 1723130025,\n",
       " 'model': 'gpt-35-turbo',\n",
       " 'object': 'chat.completion.chunk',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_811936bd4f',\n",
       " 'usage': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c621a5bd-0e3b-4662-84aa-208ea2011393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '',\n",
       " 'function_call': None,\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.choices[0].delta.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c605c3-b29c-45c5-bd1d-a6a7162d9e9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatCompletion\nchoices.0.message\n  Field required [type=missing, input_value={'delta': {'content': '',...ent_filter_results': {}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mChatCompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatCompletion\nchoices.0.message\n  Field required [type=missing, input_value={'delta': {'content': '',...ent_filter_results': {}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "ChatCompletion(**chunk.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "253cade1-da04-442f-86d3-f1e834c87a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__orig_bases__',\n",
       " '__orig_class__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__stream__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cast_to',\n",
       " '_client',\n",
       " '_decoder',\n",
       " '_is_protocol',\n",
       " '_iter_events',\n",
       " '_iterator',\n",
       " 'close',\n",
       " 'response']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_completion_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26184f27-03f6-4e2c-aea1-566ae31519fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stream' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchat_completion_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m()\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stream' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "print(chat_completion_stream.to_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3339b5-e98c-45cb-a5fc-9314cac112d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'message': {'content': '1. Scope: Azure Machine Learning is a comprehensive platform for building, training, and deploying machine learning models, while Azure AI services encompass a wider range of artificial intelligence capabilities, including machine learning, natural language processing, computer vision, and more.\\n\\n2. Functionality: Azure Machine Learning provides tools for data preparation, model training and evaluation, and model deployment, while Azure AI services offer pre-built AI models and APIs for specific tasks such as language translation, image recognition, and text analysis.\\n\\n3. Customization: Azure Machine Learning allows users to develop and customize their own machine learning models using various algorithms and techniques, while Azure AI services provide pre-built models that can be easily integrated into applications without the need for extensive customization.\\n\\n4. Complexity: Azure Machine Learning is more suitable for data scientists and machine learning experts who require a full-fledged platform for developing and deploying custom machine learning models, while Azure AI services are designed for developers who need to quickly integrate AI capabilities into their applications without extensive knowledge of machine learning.\\n\\nIn summary, Azure Machine Learning is a platform for developing custom machine learning models, while Azure AI services offer pre-built AI capabilities for specific tasks such as language processing and image recognition.',\n",
       "    'role': 'assistant'}}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(**chat_completion.dict()).dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da323a59-705c-4257-bdc6-a9a4d7a93608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c5444-74e9-4609-a98a-7b70c89132c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1ef5a-8ad6-4798-ac5a-0e46d94a6b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eba949-089f-4cff-9eea-6e1d14a7ff0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c1c42-5578-48c7-80eb-c7bf1a9dd00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf7f88-b0a7-44eb-8959-6aebbc622ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd46da31-8b97-4915-8889-d707d905f9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1106'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
