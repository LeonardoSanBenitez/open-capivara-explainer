{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd99a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs.plugin_converter.semantic_kernel_v0_to_openai_function import generate_callables, generate_definitions, make_context\n",
    "from libs.plugins.plugin_capital import PluginCapital\n",
    "from libs.plugins.plugin_salesforce import PluginSalesforce\n",
    "from libs.plugins.plugin_sap import PluginSAP\n",
    "from libs.plugins.plugin_capivara import PluginCapivaraAlert\n",
    "import libs.plugin_converter.semantic_kernel_v0_to_openai_function as semantic_kernel_v0_to_openai_function\n",
    "import libs.plugin_converter.openai_function_to_tool as openai_function_to_tool\n",
    "\n",
    "import time\n",
    "import os\n",
    "from libs.utils.connector_llm import *\n",
    "from libs.plugins.plugin_capital import PluginCapital\n",
    "import libs.plugin_converter.semantic_kernel_v0_to_openai_function as semantic_kernel_v0_to_openai_function\n",
    "import libs.plugin_converter.openai_function_to_tool as openai_function_to_tool\n",
    "from libs.plugin_orchestrator.implementation_tool import OrchestratorWithTool\n",
    "from libs.plugin_orchestrator.implementation_bare import OrchestratorBare\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58af37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semantic_kernel_v0_to_openai_function.generate_callables([(PluginSAP(), \"PluginSAP\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c94c005-eb0e-4fef-9c12-1fede9d5f2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('ca4b3593-e365-415d-8b66-f8685e159ddc')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50c4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bare openai\n",
    "#llm = factory_create_connector_llm(\n",
    "#    provider='azure_openai',\n",
    "#    modelname=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "#    version=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\").split('-')[-1],\n",
    "#    credentials=CredentialsOpenAI(\n",
    "#        base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "#    ),\n",
    "#    hyperparameters={'tool_choice': 'none'}\n",
    "#)\n",
    "\n",
    "# Tool openai\n",
    "llm = factory_create_connector_llm(\n",
    "    provider='azure_openai',\n",
    "    modelname=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "    version=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\").split('-')[-1],\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "selected_alert = {'id': 'dc2a',\n",
    " 'title': 'Defective product',\n",
    " 'description': 'I ordered a HandstÃ¼ckschlauch, but it came already broken',\n",
    " 'severity': 'Medium'}\n",
    "\n",
    "plugins = [\n",
    "    (PluginCapivaraAlert(capivara_base_url='http://capivara:80', alert_id=selected_alert['id']), \"PluginServiceNow\"),\n",
    "    (PluginSalesforce(), \"PluginSalesforce\"),\n",
    "    (PluginSAP(), \"PluginSAP\"),\n",
    "]\n",
    "orchestrator = OrchestratorWithTool(\n",
    "    connection = llm,\n",
    "    tool_definitions = openai_function_to_tool.generate_definitions(semantic_kernel_v0_to_openai_function.generate_definitions(plugins)),\n",
    "    tool_callables = generate_callables(plugins),\n",
    "    token_limit_input = 1024,\n",
    "    token_limit_output = None,\n",
    "    max_steps_recommended = 4,\n",
    "    max_steps_allowed = 5,\n",
    "    prompt_app_system=(\n",
    "        'You are an AI assistant whose goal is to help the use handle a support ticket.\\n'\n",
    "        'Here is some info about this ticket:\\n'\n",
    "        f'Title: {selected_alert[\"title\"]}\\n'\n",
    "        f'Description: {selected_alert[\"description\"]}\\n'\n",
    "        f'Severity: {selected_alert[\"severity\"]}\\n'\n",
    "        'Answer the user questions and help the user to resolve this ticket.\\n'\n",
    "    ),\n",
    "    #prompt_app_user='hi =D'  # chitchat (don't work well)\n",
    "    #prompt_app_user='What purchases have this customer done in the past?',  # SAP\n",
    "    #prompt_app_user='place an order for 10 gloves',  # SAP\n",
    "    #prompt_app_user='If the customer had purchased any glove in the past, please place an order for 100 of that exact glove model',  # SAP\n",
    "    #prompt_app_user='IF the customer purchased any hand desinfectant in the past, create an appointment for a sales call and describing we may want to do a follow up sales',  # SAP\n",
    "    #prompt_app_user='what is the full name of this customer?',  # Salesforce\n",
    "    #prompt_app_user='create an appointment asking an employee to visit the customer facility, and don\\'t forget to mention the customer address',  # Salesforce, SAP\n",
    "    prompt_app_user='close this ticket',  # Capivara\n",
    "    #prompt_app_user='place an order for 10 gloves, then close the current ticket',  # SAP, capivara\n",
    "    #prompt_app_user='If the customer had purchased any glove in the past, please place an order for 100 of that exact glove model and close the current ticket',  # SAP, capivara\n",
    ")\n",
    "\n",
    "'''\n",
    "r = await orchestrator.run_async()\n",
    "#r = orchestrator.run()\n",
    "print(r)\n",
    "print('\\n\\n' + '-'*30 + '\\n\\n')\n",
    "assert type(r.answer) == str\n",
    "assert len(r.answer) > 4\n",
    "print(r.answer)\n",
    "''';\n",
    "\n",
    "#'''\n",
    "r_stream = orchestrator.run_stream_async()\n",
    "chunks = []\n",
    "async for chunk in r_stream:\n",
    "    #print(chunk.answer, '\\t\\t| ', len(chunk.intermediate_results or []))\n",
    "    print(chunk)\n",
    "    chunks.append(chunk)\n",
    "    #time.sleep(0.1)\n",
    "#''';\n",
    "\n",
    "'''\n",
    "r_stream = orchestrator.run_stream()\n",
    "chunks = []\n",
    "for chunk in r_stream:\n",
    "    #print(chunk)\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.answer, '\\t\\t| ', len(chunk.intermediate_results or []))\n",
    "    time.sleep(0.1)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216bfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Dataset generation\n",
    "#orchestrator._full_message_history_for_debugging\n",
    "# This is the expected chat-over-text format:\n",
    "# <|system|> You are a chatbot who can help code!</s> <|user|> Write me a function to calculate the first 10 digits of the fibonacci sequence in Python and print it out to the CLI.</s> <|assistant|>\n",
    "# Before finetunning, we have to convert\n",
    "# this format is called \"Zephyr\", because it is used in the model HuggingFaceH4/zephyr-7b-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113abc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d0506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117d4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a132a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca09ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096b93e-18a0-4959-b340-321d92b140b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bare llamacpp\n",
    "'''\n",
    "llm = factory_create_connector_llm(\n",
    "    provider='llama_cpp',\n",
    "    modelname='not-needed',\n",
    "    version='not-needed',\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url='http://llm-server:8080/v1',\n",
    "        api_key='not-needed',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "plugins = [\n",
    "    (PluginCapital(), \"PluginCapital\"),\n",
    "]\n",
    "orchestrator = OrchestratorWithTool(\n",
    "    connection = llm,\n",
    "    tool_definitions = openai_function_to_tool.generate_definitions(semantic_kernel_v0_to_openai_function.generate_definitions(plugins)),\n",
    "    tool_callables = generate_callables(plugins),\n",
    "    token_limit_input = 1024,\n",
    "    token_limit_output = None,\n",
    "    max_steps_recommended = 2,\n",
    "    max_steps_allowed = 3,\n",
    "    prompt_app_system='You are an AI assistant whose goal is to answer the user question.',\n",
    "     prompt_app_user='What is the capital of france?',\n",
    ")\n",
    "\n",
    "r = await orchestrator.run_async()\n",
    "print(r)\n",
    "print('\\n\\n' + '-'*30 + '\\n\\n')\n",
    "assert type(r.answer) == str\n",
    "assert len(r.answer) > 4\n",
    "print(r.answer)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c647506-3ccc-47c6-a17f-2c4dd90f6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eee46b-9ef6-4ffb-ae4c-8aa237983e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13224931-4f2c-44cb-82d7-29053fc36f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
