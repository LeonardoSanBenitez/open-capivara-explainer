{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd99a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs.plugin_converter.semantic_kernel_v0_to_openai_function import generate_callables, generate_definitions, make_context\n",
    "from libs.plugins.plugin_capital import PluginCapital\n",
    "from libs.plugins.plugin_salesforce import PluginSalesforce\n",
    "from libs.plugins.plugin_sap import PluginSAP\n",
    "from libs.plugins.plugin_capivara import PluginCapivaraAlert\n",
    "import libs.plugin_converter.semantic_kernel_v0_to_openai_function as semantic_kernel_v0_to_openai_function\n",
    "import libs.plugin_converter.openai_function_to_tool as openai_function_to_tool\n",
    "\n",
    "import time\n",
    "import os\n",
    "from libs.utils.connector_llm import *\n",
    "from libs.plugins.plugin_capital import PluginCapital\n",
    "import libs.plugin_converter.semantic_kernel_v0_to_openai_function as semantic_kernel_v0_to_openai_function\n",
    "import libs.plugin_converter.openai_function_to_tool as openai_function_to_tool\n",
    "from libs.plugin_orchestrator.implementation_tool import OrchestratorWithTool\n",
    "from libs.plugin_orchestrator.implementation_bare import OrchestratorBare\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58af37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semantic_kernel_v0_to_openai_function.generate_callables([(PluginSAP(), \"PluginSAP\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50c4e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-24 14:49:26 +0000] libs.libs.plugin_orchestrator INFO     Function calling detected by: native API feature\n",
      "[2024-08-24 14:49:26 +0000] libs.libs.plugin_orchestrator INFO     At step 1 the function PluginServiceNow_close_ticket was requested, with args = {}\n",
      "answer=None citations=None visualizations=None intermediate_results=[IntermediateResult(step=1, status_code=200, function_name='PluginServiceNow_close_ticket', function_arguments={}, result='Ticket closed successfully', message='At step 1, executing PluginServiceNow_close_ticket', timestamp=1724510966, citation_id='933cb08f')]\n",
      "[2024-08-24 14:49:26 +0000] libs.libs.plugin_orchestrator INFO     result: Executed function PluginServiceNow_close_ticket and returned: Ticket closed successfully\n",
      "answer='I' citations=None visualizations=None intermediate_results=None\n",
      "answer=' have' citations=None visualizations=None intermediate_results=None\n",
      "answer=' closed' citations=None visualizations=None intermediate_results=None\n",
      "answer=' the' citations=None visualizations=None intermediate_results=None\n",
      "answer=' ticket' citations=None visualizations=None intermediate_results=None\n",
      "answer=' for' citations=None visualizations=None intermediate_results=None\n",
      "answer=' the' citations=None visualizations=None intermediate_results=None\n",
      "answer=' defective' citations=None visualizations=None intermediate_results=None\n",
      "answer=' product' citations=None visualizations=None intermediate_results=None\n",
      "answer='.' citations=None visualizations=None intermediate_results=None\n",
      "answer=' If' citations=None visualizations=None intermediate_results=None\n",
      "answer=' you' citations=None visualizations=None intermediate_results=None\n",
      "answer=' have' citations=None visualizations=None intermediate_results=None\n",
      "answer=' any' citations=None visualizations=None intermediate_results=None\n",
      "answer=' further' citations=None visualizations=None intermediate_results=None\n",
      "answer=' questions' citations=None visualizations=None intermediate_results=None\n",
      "answer=' or' citations=None visualizations=None intermediate_results=None\n",
      "answer=' issues' citations=None visualizations=None intermediate_results=None\n",
      "answer=',' citations=None visualizations=None intermediate_results=None\n",
      "answer=' feel' citations=None visualizations=None intermediate_results=None\n",
      "answer=' free' citations=None visualizations=None intermediate_results=None\n",
      "answer=' to' citations=None visualizations=None intermediate_results=None\n",
      "answer=' reach' citations=None visualizations=None intermediate_results=None\n",
      "answer=' out' citations=None visualizations=None intermediate_results=None\n",
      "answer='.' citations=None visualizations=None intermediate_results=None\n",
      "answer=' Thank' citations=None visualizations=None intermediate_results=None\n",
      "answer=' you' citations=None visualizations=None intermediate_results=None\n",
      "answer=' for' citations=None visualizations=None intermediate_results=None\n",
      "answer=' contacting' citations=None visualizations=None intermediate_results=None\n",
      "answer=' support' citations=None visualizations=None intermediate_results=None\n",
      "answer='.' citations=None visualizations=None intermediate_results=None\n",
      "[2024-08-24 14:49:26 +0000] libs.libs.plugin_orchestrator INFO     Function calling detected by: native API feature\n",
      "[2024-08-24 14:49:26 +0000] libs.libs.plugin_orchestrator INFO     At step 2 the function answer was requested, with args = {'text': 'I have closed the ticket for the defective product. If you have any further questions or issues, feel free to reach out. Thank you for contacting support.'}\n"
     ]
    }
   ],
   "source": [
    "# Bare openai\n",
    "#llm = factory_create_connector_llm(\n",
    "#    provider='azure_openai',\n",
    "#    modelname=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "#    version=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\").split('-')[-1],\n",
    "#    credentials=CredentialsOpenAI(\n",
    "#        base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "#    ),\n",
    "#    hyperparameters={'tool_choice': 'none'}\n",
    "#)\n",
    "\n",
    "# Tool openai\n",
    "llm = factory_create_connector_llm(\n",
    "    provider='azure_openai',\n",
    "    modelname=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"),\n",
    "    version=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\").split('-')[-1],\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "selected_alert = {'id': 'dc2a',\n",
    " 'title': 'Defective product',\n",
    " 'description': 'I ordered a HandstÃ¼ckschlauch, but it came already broken',\n",
    " 'severity': 'Medium'}\n",
    "\n",
    "plugins = [\n",
    "    (PluginCapivaraAlert(capivara_base_url='http://capivara:80', alert_id=selected_alert['id']), \"PluginServiceNow\"),\n",
    "    (PluginSalesforce(), \"PluginSalesforce\"),\n",
    "    (PluginSAP(), \"PluginSAP\"),\n",
    "]\n",
    "orchestrator = OrchestratorWithTool(\n",
    "    connection = llm,\n",
    "    tool_definitions = openai_function_to_tool.generate_definitions(semantic_kernel_v0_to_openai_function.generate_definitions(plugins)),\n",
    "    tool_callables = generate_callables(plugins),\n",
    "    token_limit_input = 1024,\n",
    "    token_limit_output = None,\n",
    "    max_steps_recommended = 4,\n",
    "    max_steps_allowed = 5,\n",
    "    prompt_app_system=(\n",
    "        'You are an AI assistant whose goal is to help the use handle a support ticket.\\n'\n",
    "        'Here is some info about this ticket:\\n'\n",
    "        f'Title: {selected_alert[\"title\"]}\\n'\n",
    "        f'Description: {selected_alert[\"description\"]}\\n'\n",
    "        f'Severity: {selected_alert[\"severity\"]}\\n'\n",
    "        'Answer the user questions and help the user to resolve this ticket.\\n'\n",
    "    ),\n",
    "    #prompt_app_user='hi =D'  # chitchat (don't work well)\n",
    "    #prompt_app_user='What purchases have this customer done in the past?',  # SAP\n",
    "    #prompt_app_user='place an order for 10 gloves',  # SAP\n",
    "    #prompt_app_user='If the customer had purchased any glove in the past, please place an order for 100 of that exact glove model',  # SAP\n",
    "    #prompt_app_user='IF the customer purchased any hand desinfectant in the past, create an appointment for a sales call and describing we may want to do a follow up sales',  # SAP\n",
    "    #prompt_app_user='what is the full name of this customer?',  # Salesforce\n",
    "    #prompt_app_user='create an appointment asking an employee to visit the customer facility, and don\\'t forget to mention the customer address',  # Salesforce, SAP\n",
    "    prompt_app_user='close this ticket',  # Capivara\n",
    "    #prompt_app_user='place an order for 10 gloves, then close the current ticket',  # SAP, capivara\n",
    "    #prompt_app_user='If the customer had purchased any glove in the past, please place an order for 100 of that exact glove model and close the current ticket',  # SAP, capivara\n",
    ")\n",
    "\n",
    "'''\n",
    "r = await orchestrator.run_async()\n",
    "#r = orchestrator.run()\n",
    "print(r)\n",
    "print('\\n\\n' + '-'*30 + '\\n\\n')\n",
    "assert type(r.answer) == str\n",
    "assert len(r.answer) > 4\n",
    "print(r.answer)\n",
    "''';\n",
    "\n",
    "#'''\n",
    "r_stream = orchestrator.run_stream_async()\n",
    "chunks = []\n",
    "async for chunk in r_stream:\n",
    "    #print(chunk.answer, '\\t\\t| ', len(chunk.intermediate_results or []))\n",
    "    print(chunk)\n",
    "    chunks.append(chunk)\n",
    "    #time.sleep(0.1)\n",
    "#''';\n",
    "\n",
    "'''\n",
    "r_stream = orchestrator.run_stream()\n",
    "chunks = []\n",
    "for chunk in r_stream:\n",
    "    #print(chunk)\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.answer, '\\t\\t| ', len(chunk.intermediate_results or []))\n",
    "    time.sleep(0.1)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe622316-a4e6-4aba-a8bc-b570c7677261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bf70c-9eef-4875-b8c8-3dd74d36bbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216bfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Dataset generation\n",
    "#orchestrator._full_message_history_for_debugging\n",
    "# This is the expected chat-over-text format:\n",
    "# <|system|> You are a chatbot who can help code!</s> <|user|> Write me a function to calculate the first 10 digits of the fibonacci sequence in Python and print it out to the CLI.</s> <|assistant|>\n",
    "# Before finetunning, we have to convert\n",
    "# this format is called \"Zephyr\", because it is used in the model HuggingFaceH4/zephyr-7b-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113abc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d0506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117d4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a132a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca09ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d818444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bare llamacpp\n",
    "'''\n",
    "llm = factory_create_connector_llm(\n",
    "    provider='llama_cpp',\n",
    "    modelname='not-needed',\n",
    "    version='not-needed',\n",
    "    credentials=CredentialsOpenAI(\n",
    "        base_url='http://llm-server:8080/v1',\n",
    "        api_key='not-needed',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "plugins = [\n",
    "    (PluginCapital(), \"PluginCapital\"),\n",
    "]\n",
    "orchestrator = OrchestratorWithTool(\n",
    "    connection = llm,\n",
    "    tool_definitions = openai_function_to_tool.generate_definitions(semantic_kernel_v0_to_openai_function.generate_definitions(plugins)),\n",
    "    tool_callables = generate_callables(plugins),\n",
    "    token_limit_input = 1024,\n",
    "    token_limit_output = None,\n",
    "    max_steps_recommended = 2,\n",
    "    max_steps_allowed = 3,\n",
    "    prompt_app_system='You are an AI assistant whose goal is to answer the user question.',\n",
    "     prompt_app_user='What is the capital of france?',\n",
    ")\n",
    "\n",
    "r = await orchestrator.run_async()\n",
    "print(r)\n",
    "print('\\n\\n' + '-'*30 + '\\n\\n')\n",
    "assert type(r.answer) == str\n",
    "assert len(r.answer) > 4\n",
    "print(r.answer)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c647506-3ccc-47c6-a17f-2c4dd90f6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eee46b-9ef6-4ffb-ae4c-8aa237983e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13224931-4f2c-44cb-82d7-29053fc36f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
